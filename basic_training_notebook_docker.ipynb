{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Initial Setup and Data Preparation\n",
    "# This cell runs the main data preparation script.\n",
    "# It ensures all necessary repositories and datasets are downloaded and processed into /data.\n",
    "import os\n",
    "import sys\n",
    "\n",
    "print(\"Starting data preparation...\")\n",
    "# Assuming prepare_local_data.py is in /data, and this notebook runs from /data as well.\n",
    "# The --data-dir /data ensures the script uses the correct base path inside Docker.\n",
    "prepare_script_path = \"/data/prepare_local_data.py\"\n",
    "if not os.path.exists(prepare_script_path):\n",
    "    # Fallback if script is in parent dir relative to /data (e.g. /prepare_local_data.py)\n",
    "    prepare_script_path = \"../prepare_local_data.py\" \n",
    "    if not os.path.exists(prepare_script_path):\n",
    "        print(f\"ERROR: {prepare_script_path} not found. Cannot prepare data.\")\n",
    "        # Consider raising an exception or sys.exit(1)\n",
    "else:\n",
    "    print(f\"Executing: !python {prepare_script_path} --data-dir /data\")\n",
    "    !python {prepare_script_path} --data-dir /data\n",
    "print(\"Data preparation script finished.\")\n",
    "\n",
    "# Ensure piper-sample-generator is in sys.path if it's used as a collection of scripts\n",
    "piper_path = \"/data/piper-sample-generator\"\n",
    "if piper_path not in sys.path:\n",
    "    sys.path.append(piper_path)\n",
    "    print(f\"Added {piper_path} to sys.path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL 2: Initial Setup and Data Preparation\n",
    "# This cell runs the main data preparation script.\n",
    "# It ensures all necessary repositories and datasets are downloaded and processed into /data.\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Current working directory: {os.getcwd()}\") # Should be /data in Docker\n",
    "\n",
    "PREPARE_DATA_SCRIPT_PATH = Path(\"/data/prepare_local_data.py\")\n",
    "DATA_DIR_INSIDE_DOCKER = Path(\"/data\") # Consistent with prepare_local_data.py's default in Docker\n",
    "\n",
    "print(f\"\\n--- Running Data Preparation Script: {PREPARE_DATA_SCRIPT_PATH} ---\")\n",
    "if PREPARE_DATA_SCRIPT_PATH.exists():\n",
    "    try:\n",
    "        completed_process = subprocess.run(\n",
    "            [sys.executable, str(PREPARE_DATA_SCRIPT_PATH), \"--data-dir\", str(DATA_DIR_INSIDE_DOCKER)],\n",
    "            capture_output=True, text=True, check=True\n",
    "        )\n",
    "        print(\"Data preparation script stdout:\")\n",
    "        print(completed_process.stdout)\n",
    "        if completed_process.stderr:\n",
    "            print(\"Data preparation script stderr:\")\n",
    "            print(completed_process.stderr)\n",
    "        print(\"Data preparation script finished successfully.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"ERROR: Data preparation script failed with exit code {e.returncode}\")\n",
    "        print(\"Stdout:\", e.stdout)\n",
    "        print(\"Stderr:\", e.stderr)\n",
    "        # In a real notebook, one might raise an error or use sys.exit here\n",
    "        # For a cell script, just printing the error might be enough.\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: Python executable not found at {sys.executable}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while running prepare_local_data.py: {e}\")\n",
    "else:\n",
    "    print(f\"ERROR: {PREPARE_DATA_SCRIPT_PATH} not found. Please ensure it's copied to /data by startup.sh.\")\n",
    "print(\"--- Data Preparation Finished ---\\n\")\n",
    "\n",
    "# Define target_word early as it's used in path definitions\n",
    "target_word = 'khum_puter'  # Phonetic spellings may produce better samples. User should change this.\n",
    "print(f\"Target wake word set to: {target_word}\")\n",
    "\n",
    "# Define base paths that subsequent cells will use\n",
    "# These are based on the structure created by prepare_local_data.py and this notebook's logic\n",
    "PIPER_SAMPLE_GENERATOR_DIR = DATA_DIR_INSIDE_DOCKER / \"piper-sample-generator\"\n",
    "# Updated generated samples directory structure as per feedback\n",
    "GENERATED_SAMPLES_BASE_DIR = DATA_DIR_INSIDE_DOCKER / \"generated_samples\" / target_word\n",
    "TEST_SAMPLE_OUTPUT_DIR = GENERATED_SAMPLES_BASE_DIR / \"test\"\n",
    "WW_SAMPLES_OUTPUT_DIR = GENERATED_SAMPLES_BASE_DIR / \"samples\"\n",
    "\n",
    "MIT_RIRS_PATH = DATA_DIR_INSIDE_DOCKER / \"mit_rirs\"\n",
    "FMA_16K_PATH = DATA_DIR_INSIDE_DOCKER / \"fma_16k\"\n",
    "AUDIOSONET_16K_PATH = DATA_DIR_INSIDE_DOCKER / \"audioset_16k\"\n",
    "AUGMENTED_FEATURES_DIR = DATA_DIR_INSIDE_DOCKER / \"generated_augmented_features\"\n",
    "NEGATIVE_DATASETS_PATH = DATA_DIR_INSIDE_DOCKER / \"negative_datasets\"\n",
    "TRAINED_MODELS_BASE_PATH = DATA_DIR_INSIDE_DOCKER / \"trained_models\" # For basic notebook\n",
    "TRAINING_CONFIG_PATH = DATA_DIR_INSIDE_DOCKER / \"training_parameters.yaml\" # For basic notebook\n",
    "\n",
    "# Ensure piper-sample-generator is in sys.path if its modules are imported directly later\n",
    "# Though for generate_samples.py, we call it as a script.\n",
    "if str(PIPER_SAMPLE_GENERATOR_DIR) not in sys.path:\n",
    "    sys.path.append(str(PIPER_SAMPLE_GENERATOR_DIR))\n",
    "    print(f\"Added {PIPER_SAMPLE_GENERATOR_DIR} to sys.path (though typically called as script)\")\n",
    "\n",
    "print(\"Initial setup cell (cell_2.py) complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL 3: Generate a larger amount of wake word samples.\n",
    "# Start here when trying to improve your model.\n",
    "# See https://github.com/kiwina/piper-sample-generator for the full set of\n",
    "# parameters. In particular, experiment with noise-scales and noise-scale-ws,\n",
    "# generating negative samples similar to the wake word, and generating many more\n",
    "# wake word samples, possibly with different phonetic pronunciations.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path # Ensure Path is imported if not already from cell_2\n",
    "\n",
    "# Variables like target_word, PIPER_SCRIPT_PATH, WW_SAMPLES_OUTPUT_DIR,\n",
    "# DATA_DIR_INSIDE_DOCKER should be defined in cell_2.py and thus available here.\n",
    "\n",
    "# Ensure the output directory for wake word samples exists\n",
    "# WW_SAMPLES_OUTPUT_DIR is defined in cell_2.py\n",
    "# Example: WW_SAMPLES_OUTPUT_DIR = DATA_DIR_INSIDE_DOCKER / \"generated_samples\" / target_word / \"samples\"\n",
    "if 'WW_SAMPLES_OUTPUT_DIR' not in globals() or 'PIPER_SCRIPT_PATH' not in globals() or 'target_word' not in globals():\n",
    "    print(\"ERROR: Essential variables (WW_SAMPLES_OUTPUT_DIR, PIPER_SCRIPT_PATH, target_word) not defined. Ensure cell_2.py ran correctly.\")\n",
    "else:\n",
    "    WW_SAMPLES_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if not PIPER_SCRIPT_PATH.exists():\n",
    "        print(f\"ERROR: Piper sample generator script not found at {PIPER_SCRIPT_PATH}. Check data preparation in cell_2.\")\n",
    "    else:\n",
    "        print(f\"Generating wake word samples for '{target_word}' into {WW_SAMPLES_OUTPUT_DIR}...\")\n",
    "        cmd_ww_samples = [\n",
    "            sys.executable, str(PIPER_SCRIPT_PATH), target_word,\n",
    "            \"--max-samples\", \"1000\", # As per original basic notebook\n",
    "            \"--batch-size\", \"100\",  # As per original basic notebook\n",
    "            \"--output-dir\", str(WW_SAMPLES_OUTPUT_DIR)\n",
    "        ]\n",
    "        try:\n",
    "            subprocess.run(cmd_ww_samples, check=True, capture_output=True, text=True)\n",
    "            print(f\"Wake word samples generated in {WW_SAMPLES_OUTPUT_DIR}\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"ERROR generating wake word samples: {e}\")\n",
    "            print(\"Stdout:\", e.stdout)\n",
    "            print(\"Stderr:\", e.stderr)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"ERROR: Python executable not found at {sys.executable} or script {PIPER_SCRIPT_PATH} not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation Data Setup\n",
    "The `prepare_local_data.py` script should have downloaded and processed all necessary augmentation data (MIT RIR, Audioset, FMA) into subdirectories within `/data`.\n",
    "The following cells will set up the augmentation using these pre-prepared datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL 4: Sets up the augmentations.\n",
    "# To improve your model, experiment with these settings and use more sources of\n",
    "# background clips.\n",
    "\n",
    "import os\n",
    "from pathlib import Path # Ensure Path is imported\n",
    "from microwakeword.audio.augmentation import Augmentation\n",
    "from microwakeword.audio.clips import Clips\n",
    "# SpectrogramGeneration is imported in a later cell where it's used.\n",
    "\n",
    "# These variables should be defined in cell_2.py and available globally in the notebook context:\n",
    "# WW_SAMPLES_OUTPUT_DIR, MIT_RIRS_PATH, FMA_16K_PATH, AUDIOSONET_16K_PATH, DATA_DIR_INSIDE_DOCKER\n",
    "\n",
    "print(\"\\n--- Setting up Augmentations ---\")\n",
    "\n",
    "# Check if essential path variables from cell_2 exist\n",
    "required_paths_for_cell_4 = {\n",
    "    \"WW_SAMPLES_OUTPUT_DIR\": WW_SAMPLES_OUTPUT_DIR if 'WW_SAMPLES_OUTPUT_DIR' in globals() else None,\n",
    "    \"MIT_RIRS_PATH\": MIT_RIRS_PATH if 'MIT_RIRS_PATH' in globals() else None,\n",
    "    \"FMA_16K_PATH\": FMA_16K_PATH if 'FMA_16K_PATH' in globals() else None,\n",
    "    \"AUDIOSONET_16K_PATH\": AUDIOSONET_16K_PATH if 'AUDIOSONET_16K_PATH' in globals() else None\n",
    "}\n",
    "\n",
    "missing_paths = [name for name, path in required_paths_for_cell_4.items() if path is None or not Path(path).exists()]\n",
    "\n",
    "if missing_paths:\n",
    "    print(f\"ERROR: One or more required data paths are missing or not defined from cell_2: {', '.join(missing_paths)}\")\n",
    "    print(\"Please ensure cell_2.py (data preparation) ran successfully and all paths are correct.\")\n",
    "    # Depending on notebook execution flow, might want to raise an error or sys.exit()\n",
    "    # For now, we'll let it proceed, but Clips/Augmentation might fail.\n",
    "    clips = None\n",
    "    augmenter = None\n",
    "else:\n",
    "    print(f\"Using wake word samples from: {WW_SAMPLES_OUTPUT_DIR}\")\n",
    "    print(f\"Using MIT RIRs from: {MIT_RIRS_PATH}\")\n",
    "    print(f\"Using FMA 16k from: {FMA_16K_PATH}\")\n",
    "    print(f\"Using Audioset 16k from: {AUDIOSONET_16K_PATH}\")\n",
    "\n",
    "    clips = Clips(input_directory=str(WW_SAMPLES_OUTPUT_DIR), # Use variable from cell_2\n",
    "                  file_pattern='*.wav',\n",
    "                  max_clip_duration_s=None,\n",
    "                  remove_silence=False, # Basic notebook keeps silence for initial samples\n",
    "                  random_split_seed=10,\n",
    "                  split_count=0.1,\n",
    "                 )\n",
    "\n",
    "    augmenter = Augmentation(augmentation_duration_s=3.2,\n",
    "                             augmentation_probabilities = {\n",
    "                                    \"SevenBandParametricEQ\": 0.1,\n",
    "                                    \"TanhDistortion\": 0.1,\n",
    "                                    \"PitchShift\": 0.1,\n",
    "                                    \"BandStopFilter\": 0.1,\n",
    "                                    \"AddColorNoise\": 0.1,\n",
    "                                    \"AddBackgroundNoise\": 0.75,\n",
    "                                    \"Gain\": 1.0,\n",
    "                                    \"RIR\": 0.5,\n",
    "                                },\n",
    "                             impulse_paths = [str(MIT_RIRS_PATH)], # Use variable\n",
    "                             background_paths = [str(FMA_16K_PATH), str(AUDIOSONET_16K_PATH)], # Use variables\n",
    "                             background_min_snr_db = -5,\n",
    "                             background_max_snr_db = 10,\n",
    "                             min_jitter_s = 0.195,\n",
    "                             max_jitter_s = 0.205,\n",
    "                            )\n",
    "    print(\"Augmentation setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL 5: Augment a random clip and play it back to verify it works well\n",
    "from IPython.display import Audio, display\n",
    "from microwakeword.audio.audio_utils import save_clip\n",
    "import os\n",
    "\n",
    "augmented_clip_path = \"/data/augmented_clip_test.wav\"\n",
    "\n",
    "try:\n",
    "    random_clip = clips.get_random_clip()\n",
    "    augmented_clip = augmenter.augment_clip(random_clip)\n",
    "    save_clip(augmented_clip, augmented_clip_path)\n",
    "    print(f\"Playing augmented test clip: {augmented_clip_path}\")\n",
    "    display(Audio(augmented_clip_path, autoplay=True))\n",
    "except Exception as e:\n",
    "    print(f\"Error during test augmentation: {e}. Check if previous cells ran successfully and data paths are correct.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL 6: Augment samples and save the training, validation, and testing sets.\n",
    "# Validating and testing samples generated the same way can make the model\n",
    "# benchmark better than it performs in real-word use. Use real samples or TTS\n",
    "# samples generated with a different TTS engine to potentially get more accurate\n",
    "# benchmarks.\n",
    "import os\n",
    "from pathlib import Path # Ensure Path is imported\n",
    "from mmap_ninja.ragged import RaggedMmap\n",
    "from microwakeword.audio.spectrograms import SpectrogramGeneration # Ensure this is imported\n",
    "\n",
    "# These variables should be defined in cell_2.py and cell_4.py:\n",
    "# AUGMENTED_FEATURES_DIR, clips, augmenter\n",
    "\n",
    "print(\"\\n--- Generating Augmented Features for Training/Validation/Testing ---\")\n",
    "\n",
    "if 'AUGMENTED_FEATURES_DIR' not in globals() or 'clips' not in globals() or 'augmenter' not in globals():\n",
    "    print(\"ERROR: Essential variables (AUGMENTED_FEATURES_DIR, clips, augmenter) not defined. Ensure cell_2.py and cell_4.py ran correctly.\")\n",
    "else:\n",
    "    AUGMENTED_FEATURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    splits_config = [\"training\", \"validation\", \"testing\"]\n",
    "    for split_item in splits_config:\n",
    "      out_dir_split_item = AUGMENTED_FEATURES_DIR / split_item # Use variable from cell_2\n",
    "      out_dir_split_item.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "      current_split_name = \"train\"\n",
    "      current_repetition = 2\n",
    "\n",
    "      # Ensure clips and augmenter are not None (i.e., cell_4 executed successfully)\n",
    "      if clips is None or augmenter is None:\n",
    "          print(f\"Skipping feature generation for {split_item} due to missing clips or augmenter setup from cell_4.\")\n",
    "          continue\n",
    "\n",
    "      current_spectrograms = SpectrogramGeneration(clips=clips,\n",
    "                                         augmenter=augmenter,\n",
    "                                         slide_frames=10,    # Uses the same spectrogram repeatedly, just shifted over by one frame. This simulates the streaming inferences while training/validating in nonstreaming mode.\n",
    "                                         step_ms=10,\n",
    "                                         )\n",
    "      if split_item == \"validation\":\n",
    "        current_split_name = \"validation\"\n",
    "        current_repetition = 1\n",
    "      elif split_item == \"testing\":\n",
    "        current_split_name = \"test\"\n",
    "        current_repetition = 1\n",
    "        current_spectrograms = SpectrogramGeneration(clips=clips,\n",
    "                                         augmenter=augmenter,\n",
    "                                         slide_frames=1,    # The testing set uses the streaming version of the model, so no artificial repetition is necessary\n",
    "                                         step_ms=10,\n",
    "                                         )\n",
    "\n",
    "      print(f\"Generating augmented features for {current_split_name} set into {out_dir_split_item}...\")\n",
    "      try:\n",
    "        RaggedMmap.from_generator(\n",
    "            out_dir=str(out_dir_split_item / 'wakeword_mmap'), # Ensure path is string for older mmap_ninja if needed\n",
    "            sample_generator=current_spectrograms.spectrogram_generator(split=current_split_name, repeat=current_repetition),\n",
    "            batch_size=100,\n",
    "            verbose=True,\n",
    "        )\n",
    "        print(f\"Finished generating features for {current_split_name} set.\")\n",
    "      except Exception as e:\n",
    "        print(f\"Error generating features for {current_split_name} set: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Datasets Setup\n",
    "The `prepare_local_data.py` script should have downloaded and extracted pre-generated negative spectrogram features into `/data/negative_datasets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL 7: Save a yaml config that controls the training process\n",
    "# These hyperparamters can make a huge different in model quality.\n",
    "# Experiment with sampling and penalty weights and increasing the number of\n",
    "# training steps.\n",
    "import yaml\n",
    "import os\n",
    "from pathlib import Path # Ensure Path is imported\n",
    "\n",
    "# These variables should be defined in cell_2.py and available globally:\n",
    "# AUGMENTED_FEATURES_DIR, NEGATIVE_DATASETS_PATH, TRAINED_MODELS_BASE_PATH, TRAINING_CONFIG_PATH\n",
    "\n",
    "print(\"\\n--- Preparing Training Configuration ---\")\n",
    "\n",
    "if 'AUGMENTED_FEATURES_DIR' not in globals() or \\\n",
    "   'NEGATIVE_DATASETS_PATH' not in globals() or \\\n",
    "   'TRAINED_MODELS_BASE_PATH' not in globals() or \\\n",
    "   'TRAINING_CONFIG_PATH' not in globals():\n",
    "    print(\"ERROR: Essential path variables for training config are not defined. Ensure cell_2.py ran correctly.\")\n",
    "    # Optionally, raise an error or sys.exit()\n",
    "    config_train = {} # Create empty config to avoid further errors if notebook continues\n",
    "else:\n",
    "    # Ensure the base training directory exists\n",
    "    (TRAINED_MODELS_BASE_PATH / \"wakeword\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    config_train = {\n",
    "        \"window_step_ms\": 10,\n",
    "        \"train_dir\": str(TRAINED_MODELS_BASE_PATH / \"wakeword\"), # Use variable\n",
    "        \"features\": [\n",
    "            {\n",
    "                \"features_dir\": str(AUGMENTED_FEATURES_DIR), # Use variable\n",
    "                \"sampling_weight\": 2.0,\n",
    "                \"penalty_weight\": 1.0,\n",
    "                \"truth\": True,\n",
    "                \"truncation_strategy\": \"truncate_start\",\n",
    "                \"type\": \"mmap\",\n",
    "            },\n",
    "            {\n",
    "                \"features_dir\": str(NEGATIVE_DATASETS_PATH / \"speech\"), # Use variable\n",
    "                \"sampling_weight\": 10.0,\n",
    "                \"penalty_weight\": 1.0,\n",
    "                \"truth\": False,\n",
    "                \"truncation_strategy\": \"random\",\n",
    "                \"type\": \"mmap\",\n",
    "            },\n",
    "            {\n",
    "                \"features_dir\": str(NEGATIVE_DATASETS_PATH / \"dinner_party\"), # Use variable\n",
    "                \"sampling_weight\": 10.0,\n",
    "                \"penalty_weight\": 1.0,\n",
    "                \"truth\": False,\n",
    "                \"truncation_strategy\": \"random\",\n",
    "                \"type\": \"mmap\",\n",
    "            },\n",
    "            {\n",
    "                \"features_dir\": str(NEGATIVE_DATASETS_PATH / \"no_speech\"), # Use variable\n",
    "                \"sampling_weight\": 5.0,\n",
    "                \"penalty_weight\": 1.0,\n",
    "                \"truth\": False,\n",
    "                \"truncation_strategy\": \"random\",\n",
    "                \"type\": \"mmap\",\n",
    "            },\n",
    "            { # Only used for validation and testing\n",
    "                \"features_dir\": str(NEGATIVE_DATASETS_PATH / \"dinner_party_eval\"), # Use variable\n",
    "                \"sampling_weight\": 0.0,\n",
    "                \"penalty_weight\": 1.0,\n",
    "                \"truth\": False,\n",
    "                \"truncation_strategy\": \"split\",\n",
    "                \"type\": \"mmap\",\n",
    "            },\n",
    "        ],\n",
    "        \"training_steps\": [10000],\n",
    "        \"positive_class_weight\": [1],\n",
    "        \"negative_class_weight\": [20],\n",
    "        \"learning_rates\": [0.001],\n",
    "        \"batch_size\": 128,\n",
    "        \"time_mask_max_size\": [0],\n",
    "        \"time_mask_count\": [0],\n",
    "        \"freq_mask_max_size\": [0],\n",
    "        \"freq_mask_count\": [0],\n",
    "        \"eval_step_interval\": 500,\n",
    "        \"clip_duration_ms\": 1500,\n",
    "        \"target_minimization\": 0.9,\n",
    "        \"minimization_metric\": None,\n",
    "        \"maximization_metric\": \"average_viable_recall\"\n",
    "    }\n",
    "\n",
    "    with open(TRAINING_CONFIG_PATH, \"w\") as file_yaml: # Use variable\n",
    "        yaml.dump(config_train, file_yaml)\n",
    "    print(f\"Training parameters saved to {TRAINING_CONFIG_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL 8: Trains a model. When finished, it will quantize and convert the model to a\n",
    "# streaming version suitable for on-device detection.\n",
    "# It will resume if stopped, but it will start over at the configured training\n",
    "# steps in the yaml file.\n",
    "# Change --train 0 to only convert and test the best-weighted model.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path # Ensure Path is imported\n",
    "\n",
    "# TRAINING_CONFIG_PATH should be defined in cell_2.py and created in cell_7.py\n",
    "# Example: TRAINING_CONFIG_PATH = DATA_DIR_INSIDE_DOCKER / \"training_parameters.yaml\"\n",
    "\n",
    "print(\"\\n--- Starting Model Training ---\")\n",
    "\n",
    "if 'TRAINING_CONFIG_PATH' not in globals() or not TRAINING_CONFIG_PATH.exists():\n",
    "    print(f\"ERROR: Training config path {TRAINING_CONFIG_PATH if 'TRAINING_CONFIG_PATH' in globals() else 'TRAINING_CONFIG_PATH variable not found'} not found or variable not defined. Ensure cell_2.py and cell_7.py ran correctly.\")\n",
    "    # In a real notebook, execution might stop here or raise an error.\n",
    "    # For a .py script representing a cell, we'll just print the error.\n",
    "else:\n",
    "    print(f\"Starting model training using config: {TRAINING_CONFIG_PATH}\")\n",
    "\n",
    "    # Construct the command string for the ! operator\n",
    "    # Ensure TRAINING_CONFIG_PATH is correctly inserted into the string.\n",
    "    # Using f-string for clarity if sys.executable is needed, or direct string construction.\n",
    "    \n",
    "    training_command = f\"\\\"{sys.executable}\\\" -m microwakeword.model_train_eval \\\\\n",
    "    --training_config='{str(TRAINING_CONFIG_PATH)}' \\\\\n",
    "    --train 1 \\\\\n",
    "    --restore_checkpoint 1 \\\\\n",
    "    --test_tf_nonstreaming 0 \\\\\n",
    "    --test_tflite_nonstreaming 0 \\\\\n",
    "    --test_tflite_nonstreaming_quantized 0 \\\\\n",
    "    --test_tflite_streaming 0 \\\\\n",
    "    --test_tflite_streaming_quantized 1 \\\\\n",
    "    --use_weights \\\"best_weights\\\" \\\\\n",
    "    mixednet \\\\\n",
    "    --pointwise_filters \\\"64,64,64,64\\\" \\\\\n",
    "    --repeat_in_block  \\\"1,1,1,1\\\" \\\\\n",
    "    --mixconv_kernel_sizes '[5],[7,11],[9,15],[23]' \\\\\n",
    "    --residual_connection \\\"0,0,0,0\\\" \\\\\n",
    "    --first_conv_filters 32 \\\\\n",
    "    --first_conv_kernel_size 5 \\\\\n",
    "    --stride 3\"\n",
    "\n",
    "    print(f\"Executing training command:\\n{training_command}\")\n",
    "    \n",
    "    # This is how you'd represent the ! command in a .py file if get_ipython() is available\n",
    "    # For direct .py execution where get_ipython is not available, this would fail.\n",
    "    # The user will convert this .py cell back to .ipynb where get_ipython().system() works.\n",
    "    if \"get_ipython\" in globals():\n",
    "        get_ipython().system(training_command)\n",
    "    else:\n",
    "        print(\"Warning: get_ipython() not available. Cannot execute training command directly in this .py script.\")\n",
    "        print(\"This cell is intended to be converted back to an .ipynb cell.\")\n",
    "        # As a fallback for pure .py script testing (though not ideal for notebook structure):\n",
    "        # import subprocess\n",
    "        # subprocess.run(training_command, shell=True, check=True)\n",
    "\n",
    "\n",
    "print(\"Model training/evaluation finished (or command printed if not in IPython).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL 9: Prepare model files for download/use\n",
    "import shutil\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path # Ensure Path is imported\n",
    "\n",
    "# Conditional import for display\n",
    "try:\n",
    "    from IPython.display import FileLink, display\n",
    "except ImportError:\n",
    "    def display(*args, **kwargs): pass\n",
    "    def FileLink(*args, **kwargs): pass\n",
    "\n",
    "# These variables should be defined in cell_2.py:\n",
    "# target_word, TRAINED_MODELS_BASE_PATH, DATA_DIR_INSIDE_DOCKER\n",
    "\n",
    "print(\"\\n--- Preparing Output Model Files ---\")\n",
    "\n",
    "if 'target_word' not in globals() or \\\n",
    "   'TRAINED_MODELS_BASE_PATH' not in globals() or \\\n",
    "   'DATA_DIR_INSIDE_DOCKER' not in globals():\n",
    "    print(\"ERROR: Essential variables (target_word, TRAINED_MODELS_BASE_PATH, DATA_DIR_INSIDE_DOCKER) not defined. Ensure cell_2.py ran correctly.\")\n",
    "else:\n",
    "    source_tflite_path = TRAINED_MODELS_BASE_PATH / \"wakeword/tflite_stream_state_internal_quant/stream_state_internal_quant.tflite\"\n",
    "    # Save final model files directly into the /data root for easy access from host\n",
    "    destination_tflite_path = DATA_DIR_INSIDE_DOCKER / f\"{target_word}_basic_model.tflite\"\n",
    "    destination_json_path = DATA_DIR_INSIDE_DOCKER / f\"{target_word}_basic_model.json\"\n",
    "\n",
    "    if source_tflite_path.exists():\n",
    "        shutil.copy(source_tflite_path, destination_tflite_path)\n",
    "        print(f\"Copied TFLite model to {destination_tflite_path}\")\n",
    "    else:\n",
    "        print(f\"ERROR: Trained TFLite model not found at {source_tflite_path}. Training might have failed or model path is incorrect.\")\n",
    "\n",
    "    json_data = {\n",
    "        \"type\": \"micro\",\n",
    "        \"wake_word\": target_word,  # Using the target_word variable from cell_2\n",
    "        \"author\": \"kiwina\", # Updated author\n",
    "        \"website\": \"https://github.com/kiwina/MicroWakeWord-Trainer-Docker\",\n",
    "        \"model\": f\"{target_word}_basic_model.tflite\", # Relative path for use with ESPHome\n",
    "        \"trained_languages\": [\"en\"],\n",
    "        \"version\": 1, # Start version at 1 for a new model\n",
    "        \"micro\": {\n",
    "            \"probability_cutoff\": 0.97, # User should adjust based on testing\n",
    "            \"sliding_window_size\": 5,\n",
    "            \"feature_step_size\": 10,\n",
    "            \"tensor_arena_size\": 30000, # User should adjust based on model needs\n",
    "            \"minimum_esphome_version\": \"2024.7.0\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    with open(destination_json_path, \"w\") as json_file:\n",
    "        json.dump(json_data, json_file, indent=2)\n",
    "    print(f\"Created JSON metadata at {destination_json_path}\")\n",
    "\n",
    "    print(\"\\n--- Script Finished (Basic Training Notebook) ---\")\n",
    "    print(f\"Output files are located in: {DATA_DIR_INSIDE_DOCKER.resolve().absolute()}\")\n",
    "    print(\"If running in Docker, this corresponds to the 'microwakeword-trainer-data' directory on your host machine.\")\n",
    "\n",
    "    if destination_tflite_path.exists():\n",
    "        print(\"\\nTFLite Model Link (for Jupyter environments):\")\n",
    "        display(FileLink(str(destination_tflite_path)))\n",
    "    if destination_json_path.exists():\n",
    "        print(\"\\nJSON Metadata Link (for Jupyter environments):\")\n",
    "        display(FileLink(str(destination_json_path)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
