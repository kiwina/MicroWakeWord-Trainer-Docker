{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c807d7ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d145ad",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# CELL 1: Initial Setup, Dependency Checks, Data Preparation Call, and Path Definitions (Basic Notebook)\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import importlib.util\n",
    "from pathlib import Path\n",
    "\n",
    "# Check for required dependencies\n",
    "def check_dependency(package_name, min_version=None):\n",
    "    \"\"\"Check if a package is installed and optionally verify its version.\"\"\"\n",
    "    try:\n",
    "        spec = importlib.util.find_spec(package_name)\n",
    "        if spec is None:\n",
    "            return False, f\"{package_name} is not installed\"\n",
    "\n",
    "        if min_version:\n",
    "            pkg = importlib.import_module(package_name)\n",
    "            version = getattr(pkg, '__version__', '0.0.0')\n",
    "            if version < min_version:\n",
    "                return False, f\"{package_name} version {version} is installed, but version {min_version} or higher is required\"\n",
    "\n",
    "        return True, f\"{package_name} is installed\"\n",
    "    except Exception as e:\n",
    "        return False, f\"Error checking {package_name}: {str(e)}\"\n",
    "\n",
    "# List of required dependencies based on requirements.txt\n",
    "required_dependencies = [\n",
    "    \"torch\",\n",
    "    \"torchaudio\",\n",
    "    \"torchvision\",\n",
    "    \"audiomentations\",\n",
    "    \"audioread\",\n",
    "    \"librosa\",\n",
    "    \"soundfile\",\n",
    "    \"soxr\",\n",
    "    \"webrtcvad\",\n",
    "    \"datasets\",\n",
    "    \"dill\",\n",
    "    \"filelock\",\n",
    "    \"fsspec\",\n",
    "    \"huggingface_hub\",\n",
    "    \"mmap_ninja\",\n",
    "    \"multiprocess\",\n",
    "    \"pandas\",\n",
    "    \"pooch\",\n",
    "    \"pyarrow\",\n",
    "    \"xxhash\",\n",
    "    \"microwakeword\"  # This should be installed from the local project via Dockerfile\n",
    "]\n",
    "\n",
    "print(\"Checking required dependencies...\")\n",
    "missing_dependencies = []\n",
    "for dep in required_dependencies:\n",
    "    is_installed, message = check_dependency(dep)\n",
    "    print(f\"  {message}\")\n",
    "    if not is_installed:\n",
    "        missing_dependencies.append(dep)\n",
    "\n",
    "if missing_dependencies:\n",
    "    print(f\"\\nWARNING: The following dependencies are missing: {', '.join(missing_dependencies)}\")\n",
    "    print(\"Some notebook cells may fail. Please ensure all dependencies are installed.\")\n",
    "    print(\"If running in Docker, these should be installed automatically via the Dockerfile.\")\n",
    "else:\n",
    "    print(\"\\nAll required dependencies are installed.\")\n",
    "\n",
    "# Conditional import for display, works in Jupyter, no-op in pure script\n",
    "try:\n",
    "    from IPython.display import Audio, display, FileLink\n",
    "except ImportError:\n",
    "    def display(*args, **kwargs): pass\n",
    "    def Audio(*args, **kwargs): pass\n",
    "    def FileLink(*args, **kwargs): pass\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Current working directory: {os.getcwd()}\") # Should be /data in Docker\n",
    "\n",
    "# --- Call External Data Preparation Script ---\n",
    "PREPARE_DATA_SCRIPT_PATH = Path(\"/data/prepare_local_data.py\")\n",
    "DATA_DIR_INSIDE_DOCKER = Path(\"/data\") # Consistent with prepare_local_data.py's default in Docker\n",
    "\n",
    "print(f\"\\n--- Running Data Preparation Script: {PREPARE_DATA_SCRIPT_PATH} ---\")\n",
    "if PREPARE_DATA_SCRIPT_PATH.exists():\n",
    "    try:\n",
    "        completed_process = subprocess.run(\n",
    "            [sys.executable, str(PREPARE_DATA_SCRIPT_PATH), \"--data-dir\", str(DATA_DIR_INSIDE_DOCKER)],\n",
    "            capture_output=True, text=True, check=True\n",
    "        )\n",
    "        print(\"Data preparation script stdout:\")\n",
    "        print(completed_process.stdout)\n",
    "        if completed_process.stderr:\n",
    "            print(\"Data preparation script stderr:\")\n",
    "            print(completed_process.stderr)\n",
    "        print(\"Data preparation script finished successfully.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"ERROR: Data preparation script failed with exit code {e.returncode}\")\n",
    "        print(\"Stdout:\", e.stdout)\n",
    "        print(\"Stderr:\", e.stderr)\n",
    "        sys.exit(f\"Data preparation failed (script error), cannot continue. Check logs for {PREPARE_DATA_SCRIPT_PATH}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: Python executable not found at {sys.executable}\")\n",
    "        sys.exit(\"Python executable not found for data prep script.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while running prepare_local_data.py: {e}\")\n",
    "        sys.exit(f\"Unexpected error running data prep script: {e}\")\n",
    "else:\n",
    "    print(f\"ERROR: {PREPARE_DATA_SCRIPT_PATH} not found. Please ensure it's copied to /data by startup.sh.\")\n",
    "    sys.exit(f\"{PREPARE_DATA_SCRIPT_PATH} not found, critical for data setup.\")\n",
    "print(\"--- Data Preparation Finished ---\\n\")\n",
    "\n",
    "# --- Define Global Paths and Variables for this Notebook ---\n",
    "target_word = 'khum_puter'  # Phonetic spellings may produce better samples. User should change this.\n",
    "print(f\"Target wake word set to: {target_word}\")\n",
    "\n",
    "PIPER_SAMPLE_GENERATOR_DIR = DATA_DIR_INSIDE_DOCKER / \"piper-sample-generator\"\n",
    "PIPER_SCRIPT_PATH = PIPER_SAMPLE_GENERATOR_DIR / \"generate_samples.py\"\n",
    "\n",
    "# Updated generated samples directory structure as per feedback\n",
    "GENERATED_SAMPLES_BASE_DIR = DATA_DIR_INSIDE_DOCKER / \"generated_samples\" / target_word\n",
    "TEST_SAMPLE_OUTPUT_DIR = GENERATED_SAMPLES_BASE_DIR / \"test\"\n",
    "WW_SAMPLES_OUTPUT_DIR = GENERATED_SAMPLES_BASE_DIR / \"samples\"\n",
    "\n",
    "MIT_RIRS_PATH = DATA_DIR_INSIDE_DOCKER / \"mit_rirs\"\n",
    "FMA_16K_PATH = DATA_DIR_INSIDE_DOCKER / \"fma_16k\"\n",
    "AUDIOSONET_16K_PATH = DATA_DIR_INSIDE_DOCKER / \"audioset_16k\"\n",
    "AUGMENTED_FEATURES_DIR = DATA_DIR_INSIDE_DOCKER / \"generated_augmented_features\"\n",
    "NEGATIVE_DATASETS_PATH = DATA_DIR_INSIDE_DOCKER / \"negative_datasets\"\n",
    "TRAINED_MODELS_BASE_PATH = DATA_DIR_INSIDE_DOCKER / \"trained_models\" # For basic notebook\n",
    "TRAINING_CONFIG_PATH = DATA_DIR_INSIDE_DOCKER / \"training_parameters.yaml\" # For basic notebook\n",
    "\n",
    "# Ensure key directories exist (prepare_local_data.py handles dataset dirs)\n",
    "TEST_SAMPLE_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "WW_SAMPLES_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "AUGMENTED_FEATURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "(TRAINED_MODELS_BASE_PATH / \"wakeword\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Function to check if assets exist in the data directory\n",
    "def check_assets_exist(directory, pattern=\"*\"):\n",
    "    \"\"\"Check if assets exist in the specified directory matching the pattern.\"\"\"\n",
    "    path = Path(directory)\n",
    "    if not path.exists():\n",
    "        return False, 0\n",
    "    \n",
    "    files = list(path.glob(pattern))\n",
    "    return len(files) > 0, len(files)\n",
    "\n",
    "# Add piper-sample-generator to sys.path if its modules are imported directly later\n",
    "if str(PIPER_SAMPLE_GENERATOR_DIR) not in sys.path:\n",
    "    sys.path.append(str(PIPER_SAMPLE_GENERATOR_DIR))\n",
    "    print(f\"Added {PIPER_SAMPLE_GENERATOR_DIR} to sys.path\")\n",
    "\n",
    "print(\"Initial setup cell (cell_1.py) complete: Data prep called and paths defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a6bb89",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# CELL 2: Generate 1 test sample of the target word for manual verification.\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path # Ensure Path is imported\n",
    "\n",
    "# Conditional import for display\n",
    "try:\n",
    "    from IPython.display import Audio, display\n",
    "except ImportError:\n",
    "    def display(*args, **kwargs): pass\n",
    "    def Audio(*args, **kwargs): pass\n",
    "\n",
    "# Check for torch dependency which is required by piper-sample-generator\n",
    "try:\n",
    "    import torch\n",
    "    torch_available = True\n",
    "except ImportError:\n",
    "    torch_available = False\n",
    "    print(\"ERROR: PyTorch is not installed. Sample generation will fail.\")\n",
    "    print(\"Please install PyTorch with: pip install torch torchaudio torchvision\")\n",
    "\n",
    "# Variables from cell_1.py:\n",
    "# target_word, PIPER_SCRIPT_PATH, TEST_SAMPLE_OUTPUT_DIR\n",
    "\n",
    "print(f\"\\n--- Generating Test Sample for '{target_word}' ---\")\n",
    "\n",
    "if 'PIPER_SCRIPT_PATH' not in globals() or \\\n",
    "   'target_word' not in globals() or \\\n",
    "   'TEST_SAMPLE_OUTPUT_DIR' not in globals():\n",
    "    print(\"ERROR: Essential variables (PIPER_SCRIPT_PATH, target_word, TEST_SAMPLE_OUTPUT_DIR) not defined. Ensure cell_1.py ran correctly.\")\n",
    "else:\n",
    "    # Ensure the output directory exists (it should have been created in cell_1)\n",
    "    TEST_SAMPLE_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Check if test sample already exists (asset caching)\n",
    "    assets_exist, file_count = check_assets_exist(TEST_SAMPLE_OUTPUT_DIR, \"*.wav\")\n",
    "    if assets_exist:\n",
    "        print(f\"Found {file_count} existing test samples in {TEST_SAMPLE_OUTPUT_DIR}\")\n",
    "        audio_path_test = next(TEST_SAMPLE_OUTPUT_DIR.glob(\"*.wav\"))\n",
    "        print(f\"Using existing test sample: {audio_path_test}\")\n",
    "        display(Audio(str(audio_path_test), autoplay=True))\n",
    "    elif not torch_available:\n",
    "        print(\"Skipping sample generation due to missing PyTorch dependency.\")\n",
    "    elif not PIPER_SCRIPT_PATH.exists():\n",
    "        print(f\"ERROR: Piper sample generator script not found at {PIPER_SCRIPT_PATH}. Check data preparation in cell_1.\")\n",
    "    else:\n",
    "        # Construct the command string for the ! operator\n",
    "        test_sample_cmd = f\"\\\"{sys.executable}\\\" \\\"{str(PIPER_SCRIPT_PATH)}\\\" \\\"{target_word}\\\" \\\n",
    "--max-samples 1 \\\n",
    "--batch-size 1 \\\n",
    "--output-dir \\\"{str(TEST_SAMPLE_OUTPUT_DIR)}\\\"\"\n",
    "\n",
    "        print(f\"Executing: {test_sample_cmd}\")\n",
    "        try:\n",
    "            if \"get_ipython\" in globals():\n",
    "                get_ipython().system(test_sample_cmd)\n",
    "            else:\n",
    "                print(\"Warning: get_ipython() not available. Cannot execute command directly in this .py script.\")\n",
    "                # Fallback for pure .py script testing (though not ideal for notebook structure):\n",
    "                # import subprocess\n",
    "                # subprocess.run(test_sample_cmd, shell=True, check=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error executing sample generation command: {e}\")\n",
    "            print(\"This might be due to missing dependencies or configuration issues.\")\n",
    "\n",
    "        audio_path_test = TEST_SAMPLE_OUTPUT_DIR / \"0.wav\"\n",
    "        if audio_path_test.exists():\n",
    "            print(f\"Playing test sample: {audio_path_test}\")\n",
    "            display(Audio(str(audio_path_test), autoplay=True))\n",
    "        else:\n",
    "            print(f\"Audio file not found at {audio_path_test}. Sample generation might have failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e70f07",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# CELL 3: Generate a larger amount of wake word samples.\n",
    "# Start here when trying to improve your model.\n",
    "# See https://github.com/kiwina/piper-sample-generator for the full set of\n",
    "# parameters. In particular, experiment with noise-scales and noise-scale-ws,\n",
    "# generating negative samples similar to the wake word, and generating many more\n",
    "# wake word samples, possibly with different phonetic pronunciations.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path # Ensure Path is imported if not already from cell_2\n",
    "\n",
    "# Check for torch dependency which is required by piper-sample-generator\n",
    "try:\n",
    "    import torch\n",
    "    torch_available = True\n",
    "except ImportError:\n",
    "    torch_available = False\n",
    "    print(\"ERROR: PyTorch is not installed. Sample generation will fail.\")\n",
    "    print(\"Please install PyTorch with: pip install torch torchaudio torchvision\")\n",
    "\n",
    "# Variables like target_word, PIPER_SCRIPT_PATH, WW_SAMPLES_OUTPUT_DIR,\n",
    "# DATA_DIR_INSIDE_DOCKER should be defined in cell_1.py and thus available here.\n",
    "\n",
    "print(\"\\n--- Generating Wake Word Samples ---\")\n",
    "\n",
    "# Ensure the output directory for wake word samples exists\n",
    "if 'WW_SAMPLES_OUTPUT_DIR' not in globals() or 'PIPER_SCRIPT_PATH' not in globals() or 'target_word' not in globals():\n",
    "    print(\"ERROR: Essential variables (WW_SAMPLES_OUTPUT_DIR, PIPER_SCRIPT_PATH, target_word) not defined. Ensure cell_1.py ran correctly.\")\n",
    "else:\n",
    "    WW_SAMPLES_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Check if wake word samples already exist (asset caching)\n",
    "    assets_exist, file_count = check_assets_exist(WW_SAMPLES_OUTPUT_DIR, \"*.wav\")\n",
    "    if assets_exist:\n",
    "        print(f\"Found {file_count} existing wake word samples in {WW_SAMPLES_OUTPUT_DIR}\")\n",
    "        print(\"Skipping generation of new samples. Delete the directory if you want to regenerate.\")\n",
    "    elif not torch_available:\n",
    "        print(\"Skipping sample generation due to missing PyTorch dependency.\")\n",
    "    elif not PIPER_SCRIPT_PATH.exists():\n",
    "        print(f\"ERROR: Piper sample generator script not found at {PIPER_SCRIPT_PATH}. Check data preparation in cell_1.\")\n",
    "    else:\n",
    "        print(f\"Generating wake word samples for '{target_word}' into {WW_SAMPLES_OUTPUT_DIR}...\")\n",
    "        cmd_ww_samples = [\n",
    "            sys.executable, str(PIPER_SCRIPT_PATH), target_word,\n",
    "            \"--max-samples\", \"1000\", # As per original basic notebook\n",
    "            \"--batch-size\", \"100\",  # As per original basic notebook\n",
    "            \"--output-dir\", str(WW_SAMPLES_OUTPUT_DIR)\n",
    "        ]\n",
    "        try:\n",
    "            subprocess.run(cmd_ww_samples, check=True, capture_output=True, text=True)\n",
    "            print(f\"Wake word samples generated in {WW_SAMPLES_OUTPUT_DIR}\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"ERROR generating wake word samples: {e}\")\n",
    "            print(\"Stdout:\", e.stdout)\n",
    "            print(\"Stderr:\", e.stderr)\n",
    "            print(\"This might be due to missing dependencies or configuration issues.\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"ERROR: Python executable not found at {sys.executable} or script {PIPER_SCRIPT_PATH} not found.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error during sample generation: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9c66f7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# CELL 4: Sets up the augmentations.\n",
    "# To improve your model, experiment with these settings and use more sources of\n",
    "# background clips.\n",
    "\n",
    "import os\n",
    "from pathlib import Path # Ensure Path is imported\n",
    "from microwakeword.audio.augmentation import Augmentation\n",
    "from microwakeword.audio.clips import Clips\n",
    "# SpectrogramGeneration is imported in a later cell where it's used.\n",
    "\n",
    "# These variables should be defined in cell_1.py and available globally in the notebook context:\n",
    "# WW_SAMPLES_OUTPUT_DIR, MIT_RIRS_PATH, FMA_16K_PATH, AUDIOSONET_16K_PATH, DATA_DIR_INSIDE_DOCKER\n",
    "\n",
    "print(\"\\n--- Setting up Augmentations ---\")\n",
    "\n",
    "# Check if essential path variables from cell_1 exist\n",
    "required_paths_for_cell_4 = {\n",
    "    \"WW_SAMPLES_OUTPUT_DIR\": WW_SAMPLES_OUTPUT_DIR if 'WW_SAMPLES_OUTPUT_DIR' in globals() else None,\n",
    "    \"MIT_RIRS_PATH\": MIT_RIRS_PATH if 'MIT_RIRS_PATH' in globals() else None,\n",
    "    \"FMA_16K_PATH\": FMA_16K_PATH if 'FMA_16K_PATH' in globals() else None,\n",
    "    \"AUDIOSONET_16K_PATH\": AUDIOSONET_16K_PATH if 'AUDIOSONET_16K_PATH' in globals() else None\n",
    "}\n",
    "\n",
    "missing_paths = [name for name, path in required_paths_for_cell_4.items() if path is None or not Path(path).exists()]\n",
    "\n",
    "if missing_paths:\n",
    "    print(f\"ERROR: One or more required data paths are missing or not defined from cell_1: {', '.join(missing_paths)}\")\n",
    "    print(\"Please ensure cell_1.py (data preparation) ran successfully and all paths are correct.\")\n",
    "    # Depending on notebook execution flow, might want to raise an error or sys.exit()\n",
    "    # For now, we'll let it proceed, but Clips/Augmentation might fail.\n",
    "    clips = None\n",
    "    augmenter = None\n",
    "else:\n",
    "    print(f\"Using wake word samples from: {WW_SAMPLES_OUTPUT_DIR}\")\n",
    "    print(f\"Using MIT RIRs from: {MIT_RIRS_PATH}\")\n",
    "    print(f\"Using FMA 16k from: {FMA_16K_PATH}\")\n",
    "    print(f\"Using Audioset 16k from: {AUDIOSONET_16K_PATH}\")\n",
    "\n",
    "    clips = Clips(input_directory=str(WW_SAMPLES_OUTPUT_DIR), # Use variable from cell_1\n",
    "                  file_pattern='*.wav',\n",
    "                  max_clip_duration_s=None,\n",
    "                  remove_silence=False, # Basic notebook keeps silence for initial samples\n",
    "                  random_split_seed=10,\n",
    "                  split_count=0.1,\n",
    "                 )\n",
    "\n",
    "    augmenter = Augmentation(augmentation_duration_s=3.2,\n",
    "                             augmentation_probabilities = {\n",
    "                                    \"SevenBandParametricEQ\": 0.1,\n",
    "                                    \"TanhDistortion\": 0.1,\n",
    "                                    \"PitchShift\": 0.1,\n",
    "                                    \"BandStopFilter\": 0.1,\n",
    "                                    \"AddColorNoise\": 0.1,\n",
    "                                    \"AddBackgroundNoise\": 0.75,\n",
    "                                    \"Gain\": 1.0,\n",
    "                                    \"RIR\": 0.5,\n",
    "                                },\n",
    "                             impulse_paths = [str(MIT_RIRS_PATH)], # Use variable\n",
    "                             background_paths = [str(FMA_16K_PATH), str(AUDIOSONET_16K_PATH)], # Use variables\n",
    "                             background_min_snr_db = -5,\n",
    "                             background_max_snr_db = 10,\n",
    "                             min_jitter_s = 0.195,\n",
    "                             max_jitter_s = 0.205,\n",
    "                            )\n",
    "    print(\"Augmentation setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d97d20",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# CELL 5: Augment a random clip and play it back to verify it works well\n",
    "from IPython.display import Audio, display\n",
    "from microwakeword.audio.audio_utils import save_clip\n",
    "import os\n",
    "\n",
    "augmented_clip_path = \"/data/augmented_clip_test.wav\"\n",
    "\n",
    "try:\n",
    "    random_clip = clips.get_random_clip()\n",
    "    augmented_clip = augmenter.augment_clip(random_clip)\n",
    "    save_clip(augmented_clip, augmented_clip_path)\n",
    "    print(f\"Playing augmented test clip: {augmented_clip_path}\")\n",
    "    display(Audio(augmented_clip_path, autoplay=True))\n",
    "except Exception as e:\n",
    "    print(f\"Error during test augmentation: {e}. Check if previous cells ran successfully and data paths are correct.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42edef38",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# CELL 6: Augment samples and save the training, validation, and testing sets.\n",
    "# Validating and testing samples generated the same way can make the model\n",
    "# benchmark better than it performs in real-word use. Use real samples or TTS\n",
    "# samples generated with a different TTS engine to potentially get more accurate\n",
    "# benchmarks.\n",
    "import os\n",
    "from pathlib import Path # Ensure Path is imported\n",
    "from mmap_ninja.ragged import RaggedMmap\n",
    "from microwakeword.audio.spectrograms import SpectrogramGeneration # Ensure this is imported\n",
    "\n",
    "# These variables should be defined in cell_1.py and cell_4.py:\n",
    "# AUGMENTED_FEATURES_DIR, clips, augmenter\n",
    "\n",
    "print(\"\\n--- Generating Augmented Features for Training/Validation/Testing ---\")\n",
    "\n",
    "if 'AUGMENTED_FEATURES_DIR' not in globals() or 'clips' not in globals() or 'augmenter' not in globals():\n",
    "    print(\"ERROR: Essential variables (AUGMENTED_FEATURES_DIR, clips, augmenter) not defined. Ensure cell_1.py and cell_4.py ran correctly.\")\n",
    "else:\n",
    "    AUGMENTED_FEATURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    splits_config = [\"training\", \"validation\", \"testing\"]\n",
    "    for split_item in splits_config:\n",
    "      out_dir_split_item = AUGMENTED_FEATURES_DIR / split_item # Use variable from cell_1\n",
    "      out_dir_split_item.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "      current_split_name = \"train\"\n",
    "      current_repetition = 2\n",
    "\n",
    "      # Ensure clips and augmenter are not None (i.e., cell_4 executed successfully)\n",
    "      if clips is None or augmenter is None:\n",
    "          print(f\"Skipping feature generation for {split_item} due to missing clips or augmenter setup from cell_4.\")\n",
    "          continue\n",
    "\n",
    "      current_spectrograms = SpectrogramGeneration(clips=clips,\n",
    "                                         augmenter=augmenter,\n",
    "                                         slide_frames=10,    # Uses the same spectrogram repeatedly, just shifted over by one frame. This simulates the streaming inferences while training/validating in nonstreaming mode.\n",
    "                                         step_ms=10,\n",
    "                                         )\n",
    "      if split_item == \"validation\":\n",
    "        current_split_name = \"validation\"\n",
    "        current_repetition = 1\n",
    "      elif split_item == \"testing\":\n",
    "        current_split_name = \"test\"\n",
    "        current_repetition = 1\n",
    "        current_spectrograms = SpectrogramGeneration(clips=clips,\n",
    "                                         augmenter=augmenter,\n",
    "                                         slide_frames=1,    # The testing set uses the streaming version of the model, so no artificial repetition is necessary\n",
    "                                         step_ms=10,\n",
    "                                         )\n",
    "\n",
    "      print(f\"Generating augmented features for {current_split_name} set into {out_dir_split_item}...\")\n",
    "      try:\n",
    "        RaggedMmap.from_generator(\n",
    "            out_dir=str(out_dir_split_item / 'wakeword_mmap'), # Ensure path is string for older mmap_ninja if needed\n",
    "            sample_generator=current_spectrograms.spectrogram_generator(split=current_split_name, repeat=current_repetition),\n",
    "            batch_size=100,\n",
    "            verbose=True,\n",
    "        )\n",
    "        print(f\"Finished generating features for {current_split_name} set.\")\n",
    "      except Exception as e:\n",
    "        print(f\"Error generating features for {current_split_name} set: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a65f3c8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# CELL 7: Save a yaml config that controls the training process\n",
    "# These hyperparamters can make a huge different in model quality.\n",
    "# Experiment with sampling and penalty weights and increasing the number of\n",
    "# training steps.\n",
    "import yaml\n",
    "import os\n",
    "from pathlib import Path # Ensure Path is imported\n",
    "\n",
    "# These variables should be defined in cell_1.py and available globally:\n",
    "# AUGMENTED_FEATURES_DIR, NEGATIVE_DATASETS_PATH, TRAINED_MODELS_BASE_PATH, TRAINING_CONFIG_PATH\n",
    "\n",
    "print(\"\\n--- Preparing Training Configuration ---\")\n",
    "\n",
    "if 'AUGMENTED_FEATURES_DIR' not in globals() or \\\n",
    "   'NEGATIVE_DATASETS_PATH' not in globals() or \\\n",
    "   'TRAINED_MODELS_BASE_PATH' not in globals() or \\\n",
    "   'TRAINING_CONFIG_PATH' not in globals():\n",
    "    print(\"ERROR: Essential path variables for training config are not defined. Ensure cell_1.py ran correctly.\")\n",
    "    # Optionally, raise an error or sys.exit()\n",
    "    config_train = {} # Create empty config to avoid further errors if notebook continues\n",
    "else:\n",
    "    # Ensure the base training directory exists\n",
    "    (TRAINED_MODELS_BASE_PATH / \"wakeword\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    config_train = {\n",
    "        \"window_step_ms\": 10,\n",
    "        \"train_dir\": str(TRAINED_MODELS_BASE_PATH / \"wakeword\"), # Use variable\n",
    "        \"features\": [\n",
    "            {\n",
    "                \"features_dir\": str(AUGMENTED_FEATURES_DIR), # Use variable\n",
    "                \"sampling_weight\": 2.0,\n",
    "                \"penalty_weight\": 1.0,\n",
    "                \"truth\": True,\n",
    "                \"truncation_strategy\": \"truncate_start\",\n",
    "                \"type\": \"mmap\",\n",
    "            },\n",
    "            {\n",
    "                \"features_dir\": str(NEGATIVE_DATASETS_PATH / \"speech\"), # Use variable\n",
    "                \"sampling_weight\": 10.0,\n",
    "                \"penalty_weight\": 1.0,\n",
    "                \"truth\": False,\n",
    "                \"truncation_strategy\": \"random\",\n",
    "                \"type\": \"mmap\",\n",
    "            },\n",
    "            {\n",
    "                \"features_dir\": str(NEGATIVE_DATASETS_PATH / \"dinner_party\"), # Use variable\n",
    "                \"sampling_weight\": 10.0,\n",
    "                \"penalty_weight\": 1.0,\n",
    "                \"truth\": False,\n",
    "                \"truncation_strategy\": \"random\",\n",
    "                \"type\": \"mmap\",\n",
    "            },\n",
    "            {\n",
    "                \"features_dir\": str(NEGATIVE_DATASETS_PATH / \"no_speech\"), # Use variable\n",
    "                \"sampling_weight\": 5.0,\n",
    "                \"penalty_weight\": 1.0,\n",
    "                \"truth\": False,\n",
    "                \"truncation_strategy\": \"random\",\n",
    "                \"type\": \"mmap\",\n",
    "            },\n",
    "            { # Only used for validation and testing\n",
    "                \"features_dir\": str(NEGATIVE_DATASETS_PATH / \"dinner_party_eval\"), # Use variable\n",
    "                \"sampling_weight\": 0.0,\n",
    "                \"penalty_weight\": 1.0,\n",
    "                \"truth\": False,\n",
    "                \"truncation_strategy\": \"split\",\n",
    "                \"type\": \"mmap\",\n",
    "            },\n",
    "        ],\n",
    "        \"training_steps\": [10000],\n",
    "        \"positive_class_weight\": [1],\n",
    "        \"negative_class_weight\": [20],\n",
    "        \"learning_rates\": [0.001],\n",
    "        \"batch_size\": 128,\n",
    "        \"time_mask_max_size\": [0],\n",
    "        \"time_mask_count\": [0],\n",
    "        \"freq_mask_max_size\": [0],\n",
    "        \"freq_mask_count\": [0],\n",
    "        \"eval_step_interval\": 500,\n",
    "        \"clip_duration_ms\": 1500,\n",
    "        \"target_minimization\": 0.9,\n",
    "        \"minimization_metric\": None,\n",
    "        \"maximization_metric\": \"average_viable_recall\"\n",
    "    }\n",
    "\n",
    "    with open(TRAINING_CONFIG_PATH, \"w\") as file_yaml: # Use variable\n",
    "        yaml.dump(config_train, file_yaml)\n",
    "    print(f\"Training parameters saved to {TRAINING_CONFIG_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473813d0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# CELL 8: Trains a model. When finished, it will quantize and convert the model to a\n",
    "# streaming version suitable for on-device detection.\n",
    "# It will resume if stopped, but it will start over at the configured training\n",
    "# steps in the yaml file.\n",
    "# Change --train 0 to only convert and test the best-weighted model.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path # Ensure Path is imported\n",
    "\n",
    "# TRAINING_CONFIG_PATH should be defined in cell_1.py and created in cell_7.py\n",
    "# Example: TRAINING_CONFIG_PATH = DATA_DIR_INSIDE_DOCKER / \"training_parameters.yaml\"\n",
    "\n",
    "print(\"\\n--- Starting Model Training ---\")\n",
    "\n",
    "if 'TRAINING_CONFIG_PATH' not in globals() or not TRAINING_CONFIG_PATH.exists():\n",
    "    print(f\"ERROR: Training config path {TRAINING_CONFIG_PATH if 'TRAINING_CONFIG_PATH' in globals() else 'TRAINING_CONFIG_PATH variable not found'} not found or variable not defined. Ensure cell_1.py and cell_7.py ran correctly.\")\n",
    "    # In a real notebook, execution might stop here or raise an error.\n",
    "    # For a .py script representing a cell, we'll just print the error.\n",
    "else:\n",
    "    print(f\"Starting model training using config: {TRAINING_CONFIG_PATH}\")\n",
    "\n",
    "    # Construct the command string for the ! operator\n",
    "    # Ensure TRAINING_CONFIG_PATH is correctly inserted into the string.\n",
    "    # Using f-string for clarity if sys.executable is needed, or direct string construction.\n",
    "\n",
    "    training_command = f\"\\\"{sys.executable}\\\" -m microwakeword.model_train_eval \\\\\n",
    "    --training_config='{str(TRAINING_CONFIG_PATH)}' \\\\\n",
    "    --train 1 \\\\\n",
    "    --restore_checkpoint 1 \\\\\n",
    "    --test_tf_nonstreaming 0 \\\\\n",
    "    --test_tflite_nonstreaming 0 \\\\\n",
    "    --test_tflite_nonstreaming_quantized 0 \\\\\n",
    "    --test_tflite_streaming 0 \\\\\n",
    "    --test_tflite_streaming_quantized 1 \\\\\n",
    "    --use_weights \\\"best_weights\\\" \\\\\n",
    "    mixednet \\\\\n",
    "    --pointwise_filters \\\"64,64,64,64\\\" \\\\\n",
    "    --repeat_in_block  \\\"1,1,1,1\\\" \\\\\n",
    "    --mixconv_kernel_sizes '[5],[7,11],[9,15],[23]' \\\\\n",
    "    --residual_connection \\\"0,0,0,0\\\" \\\\\n",
    "    --first_conv_filters 32 \\\\\n",
    "    --first_conv_kernel_size 5 \\\\\n",
    "    --stride 3\"\n",
    "\n",
    "    print(f\"Executing training command:\\n{training_command}\")\n",
    "\n",
    "    # This is how you'd represent the ! command in a .py file if get_ipython() is available\n",
    "    # For direct .py execution where get_ipython is not available, this would fail.\n",
    "    # The user will convert this .py cell back to .ipynb where get_ipython().system() works.\n",
    "    if \"get_ipython\" in globals():\n",
    "        get_ipython().system(training_command)\n",
    "    else:\n",
    "        print(\"Warning: get_ipython() not available. Cannot execute training command directly in this .py script.\")\n",
    "        print(\"This cell is intended to be converted back to an .ipynb cell.\")\n",
    "        # As a fallback for pure .py script testing (though not ideal for notebook structure):\n",
    "        # import subprocess\n",
    "        # subprocess.run(training_command, shell=True, check=True)\n",
    "\n",
    "\n",
    "print(\"Model training/evaluation finished (or command printed if not in IPython).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5defe57b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# CELL 9: Prepare model files for download/use\n",
    "import shutil\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path # Ensure Path is imported\n",
    "\n",
    "# Conditional import for display\n",
    "try:\n",
    "    from IPython.display import FileLink, display\n",
    "except ImportError:\n",
    "    def display(*args, **kwargs): pass\n",
    "    def FileLink(*args, **kwargs): pass\n",
    "\n",
    "# These variables should be defined in cell_1.py:\n",
    "# target_word, TRAINED_MODELS_BASE_PATH, DATA_DIR_INSIDE_DOCKER\n",
    "\n",
    "print(\"\\n--- Preparing Output Model Files ---\")\n",
    "\n",
    "if 'target_word' not in globals() or \\\n",
    "   'TRAINED_MODELS_BASE_PATH' not in globals() or \\\n",
    "   'DATA_DIR_INSIDE_DOCKER' not in globals():\n",
    "    print(\"ERROR: Essential variables (target_word, TRAINED_MODELS_BASE_PATH, DATA_DIR_INSIDE_DOCKER) not defined. Ensure cell_1.py ran correctly.\")\n",
    "else:\n",
    "    source_tflite_path = TRAINED_MODELS_BASE_PATH / \"wakeword/tflite_stream_state_internal_quant/stream_state_internal_quant.tflite\"\n",
    "    # Save final model files directly into the /data root for easy access from host\n",
    "    destination_tflite_path = DATA_DIR_INSIDE_DOCKER / f\"{target_word}_basic_model.tflite\"\n",
    "    destination_json_path = DATA_DIR_INSIDE_DOCKER / f\"{target_word}_basic_model.json\"\n",
    "\n",
    "    if source_tflite_path.exists():\n",
    "        shutil.copy(source_tflite_path, destination_tflite_path)\n",
    "        print(f\"Copied TFLite model to {destination_tflite_path}\")\n",
    "    else:\n",
    "        print(f\"ERROR: Trained TFLite model not found at {source_tflite_path}. Training might have failed or model path is incorrect.\")\n",
    "\n",
    "    json_data = {\n",
    "        \"type\": \"micro\",\n",
    "        \"wake_word\": target_word,  # Using the target_word variable from cell_1\n",
    "        \"author\": \"kiwina\", # Updated author\n",
    "        \"website\": \"https://github.com/kiwina/MicroWakeWord-Trainer-Docker\",\n",
    "        \"model\": f\"{target_word}_basic_model.tflite\", # Relative path for use with ESPHome\n",
    "        \"trained_languages\": [\"en\"],\n",
    "        \"version\": 1, # Start version at 1 for a new model\n",
    "        \"micro\": {\n",
    "            \"probability_cutoff\": 0.97, # User should adjust based on testing\n",
    "            \"sliding_window_size\": 5,\n",
    "            \"feature_step_size\": 10,\n",
    "            \"tensor_arena_size\": 30000, # User should adjust based on model needs\n",
    "            \"minimum_esphome_version\": \"2024.7.0\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    with open(destination_json_path, \"w\") as json_file:\n",
    "        json.dump(json_data, json_file, indent=2)\n",
    "    print(f\"Created JSON metadata at {destination_json_path}\")\n",
    "\n",
    "    print(\"\\n--- Script Finished (Basic Training Notebook) ---\")\n",
    "    print(f\"Output files are located in: {DATA_DIR_INSIDE_DOCKER.resolve().absolute()}\")\n",
    "    print(\"If running in Docker, this corresponds to the 'microwakeword-trainer-data' directory on your host machine.\")\n",
    "\n",
    "    if destination_tflite_path.exists():\n",
    "        print(\"\\nTFLite Model Link (for Jupyter environments):\")\n",
    "        display(FileLink(str(destination_tflite_path)))\n",
    "    if destination_json_path.exists():\n",
    "        print(\"\\nJSON Metadata Link (for Jupyter environments):\")\n",
    "        display(FileLink(str(destination_json_path)))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
